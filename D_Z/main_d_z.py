"""
–í–ï–õ–ò–ö–ò–ô –ü–ê–†–°–ï–† –¶–ò–¢–ê–¢ - –®–ï–î–ï–í–† –ö–û–î–ê
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç–æ–≤ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Å –≥–æ—Ç–æ–≤—ã–º–∏ –∞–¥—Ä–µ—Å–∞–º–∏
"""

import requests
import time
import json
import csv
import argparse
import logging
import sys
import os
import re
from urllib.robotparser import RobotFileParser
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from tqdm import tqdm
from functools import wraps
import signal
from datetime import datetime
from typing import List, Dict, Optional, Any
import hashlib

# ===== –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =====
DEFAULT_CONFIG = {
    "request_timeout": 15,
    "max_retries": 3,
    "retry_delay": 2,
    "user_agent": "UniversalQuoteParser/2.0 (+https://github.com/quote-parser)",
    "respect_robots": True,
    "min_quote_length": 10,
    "max_quote_length": 1000,
    "default_delay": 1
}

# –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ê–î–†–ï–°–ê –î–õ–Ø –ü–ê–†–°–ò–ù–ì–ê
AUTO_URLS = [
    "http://quotes.toscrape.com",
    "http://quotes.toscrape.com/tag/inspirational/",
    "http://quotes.toscrape.com/tag/love/",
    "http://quotes.toscrape.com/tag/life/",
    "http://quotes.toscrape.com/tag/humor/",
    "http://quotes.toscrape.com/tag/books/",
    "http://quotes.toscrape.com/tag/reading/",
    "http://quotes.toscrape.com/tag/friendship/",
    "http://quotes.toscrape.com/tag/friends/",
    "http://quotes.toscrape.com/tag/truth/"
]

SUPPORTED_SITES = {
    "toscrape": {
        "name": "Quotes to Scrape",
        "base_url": "http://quotes.toscrape.com",
        "selectors": {
            "quotes": "div.quote",
            "text": "span.text",
            "author": "small.author",
            "tags": "a.tag",
            "next_page": "li.next a"
        }
    }
}


class ConfigManager:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""

    def __init__(self, config_file: Optional[str] = None):
        self.settings = DEFAULT_CONFIG.copy()
        self.config_file = config_file
        if config_file:
            self.load_config(config_file)

    def load_config(self, config_file: str) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                user_config = json.load(f)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            validated_config = self._validate_config(user_config)
            self.settings.update(validated_config)

            logger.info(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {config_file}")
            return True

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}. –ò—Å–ø–æ–ª—å–∑—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return False

    def _validate_config(self, config: Dict) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        validated = {}

        if "request_timeout" in config:
            timeout = max(5, min(config["request_timeout"], 60))
            validated["request_timeout"] = timeout

        if "max_retries" in config:
            retries = max(1, min(config["max_retries"], 10))
            validated["max_retries"] = retries

        if "user_agent" in config:
            validated["user_agent"] = str(config["user_agent"])

        return validated


# ===== –ü–†–û–î–í–ò–ù–£–¢–û–ï –õ–û–ì–ì–ò–†–û–í–ê–ù–ò–ï =====
def setup_logging(log_file: str = "quote_parser.log") -> logging.Logger:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""

    # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä —Å —Ü–≤–µ—Ç–∞–º–∏ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
    class ColorFormatter(logging.Formatter):
        COLORS = {
            'DEBUG': '\033[36m',  # CYAN
            'INFO': '\033[32m',  # GREEN
            'WARNING': '\033[33m',  # YELLOW
            'ERROR': '\033[31m',  # RED
            'CRITICAL': '\033[41m',  # RED BACKGROUND
            'RESET': '\033[0m'  # RESET
        }

        def format(self, record):
            log_message = super().format(record)
            if record.levelname in self.COLORS:
                return f"{self.COLORS[record.levelname]}{log_message}{self.COLORS['RESET']}"
            return log_message

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
    logger = logging.getLogger('QuoteParser')
    logger.setLevel(logging.INFO)

    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è —Ñ–∞–π–ª–∞
    file_formatter = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Ñ–∞–π–ª–∞
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(file_formatter)

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(ColorFormatter(
        '%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%H:%M:%S'
    ))

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


logger = setup_logging()


# ===== –î–ï–ö–û–†–ê–¢–û–†–´ –ò –£–¢–ò–õ–ò–¢–´ –ü–†–û–î–£–ö–¶–ò–û–ù–ù–û–ì–û –£–†–û–í–ù–Ø =====
def retry_on_failure(max_retries: int = 3, delay: float = 2,
                     exceptions: tuple = (Exception,), exponential_backoff: bool = True):
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π"""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt == max_retries - 1:
                        break

                    current_delay = delay * (2 ** attempt) if exponential_backoff else delay
                    logger.warning(
                        f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries} failed: {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {current_delay} —Å–µ–∫...")
                    time.sleep(current_delay)

            logger.error(f"‚ùå –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –æ—à–∏–±–∫–æ–π: {last_exception}")
            raise last_exception

        return wrapper

    return decorator


def graceful_shutdown(signum: int, frame: Any) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è graceful shutdown —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
    logger.info("üõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è. –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
    sys.exit(0)


# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
signal.signal(signal.SIGINT, graceful_shutdown)
signal.signal(signal.SIGTERM, graceful_shutdown)


# ===== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –ü–ê–†–°–ï–†–ê - –®–ï–î–ï–í–† –ò–ù–ñ–ï–ù–ï–†–ò–ò =====
class UniversalQuoteParser:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Ü–∏—Ç–∞—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è"""

    def __init__(self, config: ConfigManager):
        self.config = config
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': config.settings['user_agent'],
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })

        self.visited_urls = set()
        self.all_quotes = []
        self.quote_hashes = set()  # –î–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        self.stats = {
            'start_time': None,
            'total_pages': 0,
            'total_quotes': 0,
            'failed_requests': 0
        }

        logger.info("üöÄ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Ü–∏—Ç–∞—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _generate_quote_hash(self, quote_text: str, author: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Ü–∏—Ç–∞—Ç—ã"""
        content = f"{quote_text.strip().lower()}|{author.strip().lower()}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def check_robots_txt(self, base_url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ robots.txt —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if not self.config.settings['respect_robots']:
            return True

        try:
            parsed_url = urlparse(base_url)
            robots_url = f"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt"

            logger.info(f"ü§ñ –ü—Ä–æ–≤–µ—Ä—è–µ–º robots.txt: {robots_url}")
            response = self.session.get(robots_url, timeout=10)

            if response.status_code == 404:
                logger.info("‚úÖ robots.txt –Ω–µ –Ω–∞–π–¥–µ–Ω - –¥–æ—Å—Ç—É–ø —Ä–∞–∑—Ä–µ—à–µ–Ω")
                return True

            rp = RobotFileParser()
            rp.parse(response.text.splitlines())

            can_fetch = rp.can_fetch(self.config.settings['user_agent'], base_url)
            if not can_fetch:
                logger.error(f"üö´ –î–æ—Å—Ç—É–ø –∫ {base_url} –∑–∞–ø—Ä–µ—â–µ–Ω –≤ robots.txt")
            else:
                logger.info("‚úÖ Robots.txt —Ä–∞–∑—Ä–µ—à–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥")

            return can_fetch

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ robots.txt: {e}. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
            return True

    @retry_on_failure(max_retries=3, delay=2, exponential_backoff=True)
    def fetch_page(self, url: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            logger.debug(f"üåê –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            response = self.session.get(
                url,
                timeout=self.config.settings['request_timeout'],
                allow_redirects=True
            )
            response.raise_for_status()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ content-type
            content_type = response.headers.get('content-type', '')
            if 'text/html' not in content_type:
                logger.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π content-type: {content_type}")

            logger.debug(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return response.text

        except requests.exceptions.Timeout:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            raise
        except requests.exceptions.HTTPError as e:
            logger.error(f"üö´ HTTP –æ—à–∏–±–∫–∞ {e.response.status_code} –¥–ª—è {url}")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"üîå –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {url}: {e}")
            raise

    def detect_site_type(self, url: str) -> Dict[str, Any]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å–∞–π—Ç–∞ –∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        for site_id, site_config in SUPPORTED_SITES.items():
            if site_config['base_url'] in url:
                logger.info(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Å–∞–π—Ç: {site_config['name']}")
                return site_config['selectors']

        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–∞–π—Ç–æ–≤
        logger.info("üîç –ò—Å–ø–æ–ª—å–∑—É—é —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã")
        return {
            "quotes": [".quote", "[class*='quote']", "blockquote"],
            "text": [".text", ".quote-text", "span", "p"],
            "author": [".author", ".quote-author", "cite", "small"],
            "tags": [".tag", ".tags", ".keywords"],
            "next_page": [".next", "[rel='next']", ".pagination-next"]
        }

    def parse_quotes(self, html: str, selectors: Dict) -> List[Dict]:
        """–£–º–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ü–∏—Ç–∞—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        soup = BeautifulSoup(html, 'html.parser')
        quotes_data = []

        # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
        quote_containers = []
        for selector in self._ensure_list(selectors["quotes"]):
            containers = soup.select(selector)
            if containers:
                quote_containers.extend(containers)
                logger.debug(f"üéØ –ù–∞–π–¥–µ–Ω —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è —Ü–∏—Ç–∞—Ç: {selector} ({len(containers)} —à—Ç.)")
                break

        if not quote_containers:
            logger.warning("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Ü–∏—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return quotes_data

        for container in quote_containers:
            try:
                # –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–∞ —Ü–∏—Ç–∞—Ç—ã
                quote_text = self._find_element_text(container, selectors["text"])
                if not quote_text:
                    continue

                # –ü–æ–∏—Å–∫ –∞–≤—Ç–æ—Ä–∞
                author_text = self._find_element_text(container, selectors["author"]) or "Unknown"

                # –ü–æ–∏—Å–∫ —Ç–µ–≥–æ–≤
                tags = self._find_tags(container, selectors["tags"])

                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Ü–∏—Ç–∞—Ç—ã
                quote_obj = self._create_quote_object(quote_text, author_text, tags)
                if quote_obj and self._is_unique_quote(quote_obj):
                    quotes_data.append(quote_obj)

            except Exception as e:
                logger.debug(f"üîß –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ü–∏—Ç–∞—Ç—ã: {e}")
                continue

        logger.info(f"üìä –†–∞—Å–ø–∞—Ä—à–µ–Ω–æ —Ü–∏—Ç–∞—Ç: {len(quotes_data)}")
        return quotes_data

    def _ensure_list(self, selector) -> List[str]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –≤ —Å–ø–∏—Å–æ–∫"""
        if isinstance(selector, list):
            return selector
        return [selector] if selector else []

    def _find_element_text(self, container, selectors: List[str]) -> Optional[str]:
        """–ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º"""
        for selector in self._ensure_list(selectors):
            if not selector:
                continue
            element = container.select_one(selector)
            if element:
                text = element.get_text(strip=True)
                if text:
                    return text
        return None

    def _find_tags(self, container, selectors: List[str]) -> List[str]:
        """–ü–æ–∏—Å–∫ —Ç–µ–≥–æ–≤ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º"""
        tags = []
        for selector in self._ensure_list(selectors):
            if not selector:
                continue
            elements = container.select(selector)
            for element in elements:
                tag_text = element.get_text(strip=True)
                if tag_text:
                    tags.append(tag_text)
        return tags

    def _create_quote_object(self, quote_text: str, author: str, tags: List[str]) -> Optional[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞ —Ü–∏—Ç–∞—Ç—ã"""
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        quote_text = quote_text.strip()
        author = author.strip()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª–∏–Ω—ã
        min_len = self.config.settings['min_quote_length']
        max_len = self.config.settings['max_quote_length']

        if len(quote_text) < min_len or len(quote_text) > max_len:
            return None

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
        if not self._validate_quote_content(quote_text):
            return None

        return {
            'quote': quote_text,
            'author': author,
            'tags': tags,
            'tags_count': len(tags),
            'timestamp': datetime.now().isoformat()
        }

    def _validate_quote_content(self, quote_text: str) -> bool:
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Ü–∏—Ç–∞—Ç—ã"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–π —Ç–µ–∫—Å—Ç
        if quote_text.isdigit():
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        special_chars = len(re.findall(r'[^\w\s]', quote_text))
        if special_chars > len(quote_text) * 0.3:
            return False

        return True

    def _is_unique_quote(self, quote_obj: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Ü–∏—Ç–∞—Ç—ã"""
        quote_hash = self._generate_quote_hash(quote_obj['quote'], quote_obj['author'])
        if quote_hash in self.quote_hashes:
            return False

        self.quote_hashes.add(quote_hash)
        return True

    def has_next_page(self, html: str, selectors: Dict) -> Optional[str]:
        """–ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
        soup = BeautifulSoup(html, 'html.parser')

        for selector in self._ensure_list(selectors["next_page"]):
            next_element = soup.select_one(selector)
            if next_element and next_element.get('href'):
                next_url = next_element['href']
                logger.debug(f"‚û°Ô∏è –ù–∞–π–¥–µ–Ω–∞ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {next_url}")
                return next_url

        logger.debug("‚èπÔ∏è –°–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return None

    def parse_all_pages(self, start_url: str, delay: float = 1) -> None:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ –í–°–ï–• —Å—Ç—Ä–∞–Ω–∏—Ü —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º"""
        current_url = start_url
        page_count = 0
        selectors = self.detect_site_type(start_url)

        self.stats['start_time'] = datetime.now()

        logger.info(f"üéØ –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {start_url}")
        logger.info(f"‚è∞ –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {delay} —Å–µ–∫")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        with tqdm(
                desc="üåê –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü",
                unit="—Å—Ç—Ä",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]"
        ) as pbar:

            while current_url and current_url not in self.visited_urls:
                try:
                    logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_count + 1}: {current_url}")

                    # –í–µ–∂–ª–∏–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    if delay > 0 and page_count > 0:
                        time.sleep(delay)

                    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    html = self.fetch_page(current_url)
                    self.visited_urls.add(current_url)

                    quotes = self.parse_quotes(html, selectors)
                    self.all_quotes.extend(quotes)

                    new_quotes = len(quotes)
                    self.stats['total_quotes'] += new_quotes
                    self.stats['total_pages'] += 1

                    logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_count + 1}: {new_quotes} –Ω–æ–≤—ã—Ö —Ü–∏—Ç–∞—Ç")

                    # –ü–æ–∏—Å–∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    next_page = self.has_next_page(html, selectors)
                    if next_page:
                        current_url = urljoin(current_url, next_page)
                        logger.info(f"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞: {current_url}")
                    else:
                        logger.info("üèÅ –ü–∞–≥–∏–Ω–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                        break

                    page_count += 1
                    pbar.update(1)
                    pbar.set_postfix({
                        '—Ü–∏—Ç–∞—Ç': self.stats['total_quotes'],
                        '—Å—Ç—Ä–∞–Ω–∏—Ü': page_count
                    })

                except Exception as e:
                    self.stats['failed_requests'] += 1
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_url}: {e}")
                    break

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self._print_statistics()

    def _print_statistics(self) -> None:
        """–í—ã–≤–æ–¥ –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        if self.stats['start_time']:
            duration = datetime.now() - self.stats['start_time']

        logger.info("üìà === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–´–ü–û–õ–ù–ï–ù–ò–Ø ===")
        logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {self.stats['total_pages']}")
        logger.info(f"üí¨ –°–æ–±—Ä–∞–Ω–æ —Ü–∏—Ç–∞—Ç: {self.stats['total_quotes']}")
        logger.info(f"üîó –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL: {len(self.visited_urls)}")
        logger.info(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {self.stats['failed_requests']}")

        if self.stats['start_time']:
            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration}")

        if self.all_quotes:
            unique_authors = len(set(q['author'] for q in self.all_quotes))
            total_tags = sum(q['tags_count'] for q in self.all_quotes)
            logger.info(f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {unique_authors}")
            logger.info(f"üè∑Ô∏è –í—Å–µ–≥–æ —Ç–µ–≥–æ–≤: {total_tags}")

    def save_data(self, filename: str, format: str = 'json') -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        if not self.all_quotes:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return False

        try:
            base_name = filename.rsplit('.', 1)[0] if '.' in filename else filename
            output_file = f"{base_name}.{format.lower()}"

            if format.lower() == 'json':
                self._save_json(output_file)
            elif format.lower() == 'csv':
                self._save_csv(output_file)
            else:
                logger.error(f"üö´ –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")
                return False

            logger.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False

    def _save_json(self, filename: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON —Å –∫—Ä–∞—Å–∏–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        data = {
            "metadata": {
                "source": "Universal Quote Parser",
                "version": "2.0",
                "total_quotes": len(self.all_quotes),
                "total_pages": len(self.visited_urls),
                "unique_authors": len(set(q['author'] for q in self.all_quotes)),
                "timestamp": datetime.now().isoformat(),
                "execution_time": str(datetime.now() - self.stats['start_time']) if self.stats['start_time'] else None
            },
            "quotes": self.all_quotes
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, sort_keys=True)

    def _save_csv(self, filename: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        with open(filename, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['ID', 'Quote', 'Author', 'Tags', 'Tags Count', 'Timestamp'])

            for idx, quote_data in enumerate(self.all_quotes, 1):
                writer.writerow([
                    idx,
                    quote_data['quote'],
                    quote_data['author'],
                    ', '.join(quote_data['tags']),
                    quote_data['tags_count'],
                    quote_data['timestamp']
                ])

    def generate_html_report(self, filename: str = "quotes_report.html") -> bool:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —à–µ–¥–µ–≤—Ä–∞–ª—å–Ω–æ–≥–æ HTML –æ—Ç—á–µ—Ç–∞"""
        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
            stats = {
                'total_quotes': len(self.all_quotes),
                'total_pages': len(self.visited_urls),
                'unique_authors': len(set(q['author'] for q in self.all_quotes)),
                'total_tags': sum(q['tags_count'] for q in self.all_quotes),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

            html_content = self._create_html_template(stats)

            with open(filename, 'w', encoding='utf-8') as f:
                f.write(html_content)

            logger.info(f"üé® HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {filename}")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è HTML –æ—Ç—á–µ—Ç–∞: {e}")
            return False

    def _create_html_template(self, stats: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ HTML —à–∞–±–ª–æ–Ω–∞ –æ—Ç—á–µ—Ç–∞"""
        quotes_html = "".join(
            f"""
            <div class="quote-card">
                <div class="quote-text">"{quote['quote']}"</div>
                <div class="quote-author">‚Äî {quote['author']}</div>
                {f'<div class="quote-tags">{" ".join([f"<span class=\"tag\">{tag}</span>" for tag in quote["tags"]])}</div>' if quote['tags'] else ''}
            </div>
            """ for quote in self.all_quotes
        )

        return f"""
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>–û—Ç—á–µ—Ç –ø–∞—Ä—Å–µ—Ä–∞ —Ü–∏—Ç–∞—Ç</title>
    <style>
        /* –í–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–µ —Å—Ç–∏–ª–∏ —à–µ–¥–µ–≤—Ä–∞ */
        body {{
            font-family: 'Segoe UI', system-ui, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            margin: 0;
            padding: 20px;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
        }}
        .header {{
            background: rgba(255,255,255,0.95);
            padding: 3rem;
            border-radius: 20px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            backdrop-filter: blur(10px);
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1.5rem;
            margin-bottom: 3rem;
        }}
        .stat-card {{
            background: rgba(255,255,255,0.95);
            padding: 2rem;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: transform 0.3s ease;
        }}
        .stat-card:hover {{ transform: translateY(-5px); }}
        .quotes-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(400px, 1fr));
            gap: 2rem;
        }}
        .quote-card {{
            background: rgba(255,255,255,0.95);
            padding: 2.5rem;
            border-radius: 20px;
            box-shadow: 0 15px 35px rgba(0,0,0,0.1);
            border-left: 5px solid #667eea;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }}
        .quote-card:hover {{
            transform: translateY(-3px) scale(1.02);
            box-shadow: 0 25px 50px rgba(0,0,0,0.15);
        }}
        .quote-card::before {{
            content: '"';
            font-size: 8rem;
            color: #667eea;
            opacity: 0.1;
            position: absolute;
            top: -2rem;
            left: 1rem;
            font-family: Georgia;
        }}
        .quote-text {{
            font-size: 1.2rem;
            line-height: 1.6;
            color: #2c3e50;
            margin-bottom: 1.5rem;
            font-style: italic;
            position: relative;
            z-index: 1;
        }}
        .quote-author {{
            text-align: right;
            font-weight: 700;
            color: #667eea;
            font-size: 1.1rem;
            position: relative;
            z-index: 1;
        }}
        .quote-tags {{
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1rem;
        }}
        .tag {{
            background: #667eea;
            color: white;
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.8rem;
        }}
        @media (max-width: 768px) {{
            .quotes-grid {{ grid-template-columns: 1fr; }}
            .header {{ padding: 2rem 1rem; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üí´ –í–µ–ª–∏–∫–∏–π –ü–∞—Ä—Å–µ—Ä –¶–∏—Ç–∞—Ç</h1>
            <p>–®–µ–¥–µ–≤—Ä –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞</p>
        </div>

        <div class="stats">
            <div class="stat-card">
                <div class="stat-number">{stats['total_quotes']}</div>
                <div class="stat-label">–í—Å–µ–≥–æ —Ü–∏—Ç–∞—Ç</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{stats['total_pages']}</div>
                <div class="stat-label">–ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{stats['unique_authors']}</div>
                <div class="stat-label">–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{stats['total_tags']}</div>
                <div class="stat-label">–í—Å–µ–≥–æ —Ç–µ–≥–æ–≤</div>
            </div>
        </div>

        <div class="quotes-grid">
            {quotes_html}
        </div>
    </div>
</body>
</html>
        """


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–£–°–ö –° –ì–û–¢–û–í–´–ú–ò –ê–î–†–ï–°–ê–ú–ò"""

    print("üöÄ –í–ï–õ–ò–ö–ò–ô –ü–ê–†–°–ï–† –¶–ò–¢–ê–¢ - –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–£–°–ö!")
    print("=" * 60)
    print("üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏–º 10 —Ä–∞–∑–¥–µ–ª–æ–≤ quotes.toscrape.com")
    print("üìä –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —Ü–∏—Ç–∞—Ç—ã —Å–æ –í–°–ï–• —Å—Ç—Ä–∞–Ω–∏—Ü!")
    print("=" * 60)

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –∞–¥—Ä–µ—Å–∞ –±—É–¥—É—Ç –ø–∞—Ä—Å–∏—Ç—å—Å—è
    print("\nüìã –°–ü–ò–°–û–ö –ê–î–†–ï–°–û–í –î–õ–Ø –ü–ê–†–°–ò–ù–ì–ê:")
    for i, url in enumerate(AUTO_URLS, 1):
        print(f"  {i:2d}. {url}")

    print("\n‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥...")
    time.sleep(2)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = ConfigManager()

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞
    quote_parser = UniversalQuoteParser(config)

    all_results = []

    try:
        # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ü–ê–†–°–ò–ù–ì –í–°–ï–• –ê–î–†–ï–°–û–í
        for i, url in enumerate(AUTO_URLS, 1):
            try:
                print(f"\n{'=' * 50}")
                print(f"üéØ –ü–ê–†–°–ò–ù–ì {i}/{len(AUTO_URLS)}: {url}")
                print(f"{'=' * 50}")

                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
                quote_parser.visited_urls.clear()
                quote_parser.quote_hashes.clear()

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ robots.txt
                if not quote_parser.check_robots_txt(url):
                    print(f"üö´ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–ø—Ä–µ—â–µ–Ω —Ñ–∞–π–ª–æ–º robots.txt –¥–ª—è {url}")
                    continue

                # –ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                quote_parser.parse_all_pages(url, delay=1)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if quote_parser.all_quotes:
                    all_results.extend(quote_parser.all_quotes)
                    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ {len(quote_parser.all_quotes)} —Ü–∏—Ç–∞—Ç")
                else:
                    print("‚ö†Ô∏è –¶–∏—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏
                if i < len(AUTO_URLS):
                    print("‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ä–∞–∑–¥–µ–ª–æ–º...")
                    time.sleep(2)

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
                continue

        # –°–û–•–†–ê–ù–ï–ù–ò–ï –ò–¢–û–ì–û–í–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        if all_results:
            quote_parser.all_quotes = all_results

            print(f"\n{'=' * 60}")
            print("üéâ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù!")
            print(f"{'=' * 60}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            quote_parser.save_data("–í–ï–õ–ò–ö–ò–ï_–¶–ò–¢–ê–¢–´", 'json')
            quote_parser.save_data("–í–ï–õ–ò–ö–ò–ï_–¶–ò–¢–ê–¢–´", 'csv')

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞
            quote_parser.generate_html_report("–í–ï–õ–ò–ö–ò–ï_–¶–ò–¢–ê–¢–´_–û–¢–ß–ï–¢.html")

            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            unique_authors = len(set(q['author'] for q in all_results))
            total_tags = sum(q['tags_count'] for q in all_results)
            total_pages = len(quote_parser.visited_urls)

            print(f"üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            print(f"   üí¨ –í—Å–µ–≥–æ —Ü–∏—Ç–∞—Ç: {len(all_results)}")
            print(f"   üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {unique_authors}")
            print(f"   üè∑Ô∏è –í—Å–µ–≥–æ —Ç–µ–≥–æ–≤: {total_tags}")
            print(f"   üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
            print(f"   üåê –ü–∞—Ä—Å–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(AUTO_URLS)}")

            print(f"\nüìÅ –°–û–ó–î–ê–ù–ù–´–ï –§–ê–ô–õ–´:")
            print(f"   ‚Ä¢ –í–ï–õ–ò–ö–ò–ï_–¶–ò–¢–ê–¢–´.json - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            print(f"   ‚Ä¢ –í–ï–õ–ò–ö–ò–ï_–¶–ò–¢–ê–¢–´.csv - —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            print(f"   ‚Ä¢ –í–ï–õ–ò–ö–ò–ï_–¶–ò–¢–ê–¢–´_–û–¢–ß–ï–¢.html - –∫—Ä–∞—Å–∏–≤—ã–π HTML –æ—Ç—á–µ—Ç")
            print(f"   ‚Ä¢ quote_parser.log - –¥–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥ —Ä–∞–±–æ—Ç—ã")

        else:
            print("üòî –¶–∏—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –∞–¥—Ä–µ—Å–æ–≤")

    except KeyboardInterrupt:
        print("\nüõë –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()